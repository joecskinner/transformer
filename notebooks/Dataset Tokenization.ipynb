{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89dca6c-fa4c-4fd6-af5c-50cdc6a3fc5b",
   "metadata": {},
   "source": [
    "# Dataset Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f656a4-6ffd-4f10-92a9-b75c57d2463e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4ef060-8398-44d2-9efd-dcacbe210e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "import src.utils.byte_pair_encoding_tokenizer as bpe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7777009-c7fc-4c78-8a1b-cd1cb25444e0",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebca37cf-dafa-43b1-855b-d21ae5b518c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
    "train_dataset, val_dataset = dataset['train'], dataset['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70770883-07fb-4378-9961-99a6a6b62609",
   "metadata": {},
   "source": [
    "## Prepare the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dc6a3ef-787b-48f5-baff-f589a9ed9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = bpe.CustomBPETokenizer([\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"], \"bpe_tokenizers/ted_hrlr_translate_pt_to_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5a675-52ba-4625-b6df-8dd0a05139e3",
   "metadata": {},
   "source": [
    "## Tokenize and save dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c4a6adf-8741-4a3d-9c44-00c8d2130646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset, tokenizer, log, N):\n",
    "    en_tokenized_list = []\n",
    "    pt_tokenized_list = []\n",
    "\n",
    "    # Iterate through the dataset\n",
    "    count = 0\n",
    "    for pt, en in dataset:\n",
    "        # Convert tensors to strings\n",
    "        pt_str = pt.numpy().decode('utf-8')\n",
    "        en_str = en.numpy().decode('utf-8')\n",
    "        \n",
    "        # Tokenize\n",
    "        pt_tokenized = tokenizer.tokenize([pt_str])\n",
    "        en_tokenized = tokenizer.tokenize([en_str])\n",
    "        \n",
    "        pt_tokenized_list.append(pt_tokenized[0])\n",
    "        en_tokenized_list.append(en_tokenized[0])\n",
    "\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            if log:\n",
    "                print(f\"Tokenized first {count} examples...\")\n",
    "        if N is not None and count == N:\n",
    "            if log:\n",
    "                print(f\"Early exit. Tokenized first {count} examples.\")\n",
    "            break\n",
    "\n",
    "    return tf.ragged.stack(pt_tokenized_list), tf.ragged.stack(en_tokenized_list)\n",
    "\n",
    "def tokenize_and_save_dataset(dataset, tokenizer, path, log=True, N=None):\n",
    "    pt_tokenized, en_tokenized = tokenize_dataset(dataset, tokenizer, log, N)\n",
    "\n",
    "    pt_tokenized_dataset = tf.data.Dataset.from_tensor_slices(tf.concat(pt_tokenized, axis=0))\n",
    "    en_tokenized_dataset = tf.data.Dataset.from_tensor_slices(tf.concat(en_tokenized, axis=0))\n",
    "\n",
    "    combined_dataset = tf.data.Dataset.zip((pt_tokenized_dataset, en_tokenized_dataset))\n",
    "\n",
    "    combined_dataset.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dcbfdd6-0a29-424c-8a77-212cbfa2acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH =  \"./tokenized_data/train\"\n",
    "VAL_DATASET_PATH = \"./tokenized_data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7dbcaaf-e397-41ef-91a0-a892eb418157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized first 100 examples...\n",
      "Tokenized first 200 examples...\n",
      "Tokenized first 300 examples...\n",
      "Tokenized first 400 examples...\n",
      "Tokenized first 500 examples...\n",
      "Tokenized first 600 examples...\n",
      "Tokenized first 700 examples...\n",
      "Tokenized first 800 examples...\n",
      "Tokenized first 900 examples...\n",
      "Tokenized first 1000 examples...\n",
      "Tokenized first 1100 examples...\n",
      "Tokenized first 1200 examples...\n",
      "Tokenized first 1300 examples...\n",
      "Tokenized first 1400 examples...\n",
      "Tokenized first 1500 examples...\n",
      "Tokenized first 1600 examples...\n",
      "Tokenized first 1700 examples...\n",
      "Tokenized first 1800 examples...\n",
      "Tokenized first 1900 examples...\n",
      "Tokenized first 2000 examples...\n",
      "Tokenized first 2100 examples...\n",
      "Tokenized first 2200 examples...\n",
      "Tokenized first 2300 examples...\n",
      "Tokenized first 2400 examples...\n",
      "Tokenized first 2500 examples...\n",
      "Tokenized first 2600 examples...\n",
      "Tokenized first 2700 examples...\n",
      "Tokenized first 2800 examples...\n",
      "Tokenized first 2900 examples...\n",
      "Tokenized first 3000 examples...\n",
      "Tokenized first 3100 examples...\n",
      "Tokenized first 3200 examples...\n",
      "Tokenized first 3300 examples...\n",
      "Tokenized first 3400 examples...\n",
      "Tokenized first 3500 examples...\n",
      "Tokenized first 3600 examples...\n",
      "Tokenized first 3700 examples...\n",
      "Tokenized first 3800 examples...\n",
      "Tokenized first 3900 examples...\n",
      "Tokenized first 4000 examples...\n",
      "Tokenized first 4100 examples...\n",
      "Tokenized first 4200 examples...\n",
      "Tokenized first 4300 examples...\n",
      "Tokenized first 4400 examples...\n",
      "Tokenized first 4500 examples...\n",
      "Tokenized first 4600 examples...\n",
      "Tokenized first 4700 examples...\n",
      "Tokenized first 4800 examples...\n",
      "Tokenized first 4900 examples...\n",
      "Tokenized first 5000 examples...\n",
      "Tokenized first 5100 examples...\n",
      "Tokenized first 5200 examples...\n",
      "Tokenized first 5300 examples...\n",
      "Tokenized first 5400 examples...\n",
      "Tokenized first 5500 examples...\n",
      "Tokenized first 5600 examples...\n",
      "Tokenized first 5700 examples...\n",
      "Tokenized first 5800 examples...\n",
      "Tokenized first 5900 examples...\n",
      "Tokenized first 6000 examples...\n",
      "Tokenized first 6100 examples...\n",
      "Tokenized first 6200 examples...\n",
      "Tokenized first 6300 examples...\n",
      "Tokenized first 6400 examples...\n",
      "Tokenized first 6500 examples...\n",
      "Tokenized first 6600 examples...\n",
      "Tokenized first 6700 examples...\n",
      "Tokenized first 6800 examples...\n",
      "Tokenized first 6900 examples...\n",
      "Tokenized first 7000 examples...\n",
      "Tokenized first 7100 examples...\n",
      "Tokenized first 7200 examples...\n",
      "Tokenized first 7300 examples...\n",
      "Tokenized first 7400 examples...\n",
      "Tokenized first 7500 examples...\n",
      "Tokenized first 7600 examples...\n",
      "Tokenized first 7700 examples...\n",
      "Tokenized first 7800 examples...\n",
      "Tokenized first 7900 examples...\n",
      "Tokenized first 8000 examples...\n",
      "Tokenized first 8100 examples...\n",
      "Tokenized first 8200 examples...\n",
      "Tokenized first 8300 examples...\n",
      "Tokenized first 8400 examples...\n",
      "Tokenized first 8500 examples...\n",
      "Tokenized first 8600 examples...\n",
      "Tokenized first 8700 examples...\n",
      "Tokenized first 8800 examples...\n",
      "Tokenized first 8900 examples...\n",
      "Tokenized first 9000 examples...\n",
      "Tokenized first 9100 examples...\n",
      "Tokenized first 9200 examples...\n",
      "Tokenized first 9300 examples...\n",
      "Tokenized first 9400 examples...\n",
      "Tokenized first 9500 examples...\n",
      "Tokenized first 9600 examples...\n",
      "Tokenized first 9700 examples...\n",
      "Tokenized first 9800 examples...\n",
      "Tokenized first 9900 examples...\n",
      "Tokenized first 10000 examples...\n",
      "Tokenized first 10100 examples...\n",
      "Tokenized first 10200 examples...\n",
      "Tokenized first 10300 examples...\n",
      "Tokenized first 10400 examples...\n",
      "Tokenized first 10500 examples...\n",
      "Tokenized first 10600 examples...\n",
      "Tokenized first 10700 examples...\n",
      "Tokenized first 10800 examples...\n",
      "Tokenized first 10900 examples...\n",
      "Tokenized first 11000 examples...\n",
      "Tokenized first 11100 examples...\n",
      "Tokenized first 11200 examples...\n",
      "Tokenized first 11300 examples...\n",
      "Tokenized first 11400 examples...\n",
      "Tokenized first 11500 examples...\n",
      "Tokenized first 11600 examples...\n",
      "Tokenized first 11700 examples...\n",
      "Tokenized first 11800 examples...\n",
      "Tokenized first 11900 examples...\n",
      "Tokenized first 12000 examples...\n",
      "Tokenized first 12100 examples...\n",
      "Tokenized first 12200 examples...\n",
      "Tokenized first 12300 examples...\n",
      "Tokenized first 12400 examples...\n",
      "Tokenized first 12500 examples...\n",
      "Tokenized first 12600 examples...\n",
      "Tokenized first 12700 examples...\n",
      "Tokenized first 12800 examples...\n",
      "Tokenized first 12900 examples...\n",
      "Tokenized first 13000 examples...\n",
      "Tokenized first 13100 examples...\n",
      "Tokenized first 13200 examples...\n",
      "Tokenized first 13300 examples...\n",
      "Tokenized first 13400 examples...\n",
      "Tokenized first 13500 examples...\n",
      "Tokenized first 13600 examples...\n",
      "Tokenized first 13700 examples...\n",
      "Tokenized first 13800 examples...\n",
      "Tokenized first 13900 examples...\n",
      "Tokenized first 14000 examples...\n",
      "Tokenized first 14100 examples...\n",
      "Tokenized first 14200 examples...\n",
      "Tokenized first 14300 examples...\n",
      "Tokenized first 14400 examples...\n",
      "Tokenized first 14500 examples...\n",
      "Tokenized first 14600 examples...\n",
      "Tokenized first 14700 examples...\n",
      "Tokenized first 14800 examples...\n",
      "Tokenized first 14900 examples...\n",
      "Tokenized first 15000 examples...\n",
      "Tokenized first 15100 examples...\n",
      "Tokenized first 15200 examples...\n",
      "Tokenized first 15300 examples...\n",
      "Tokenized first 15400 examples...\n",
      "Tokenized first 15500 examples...\n",
      "Tokenized first 15600 examples...\n",
      "Tokenized first 15700 examples...\n",
      "Tokenized first 15800 examples...\n",
      "Tokenized first 15900 examples...\n",
      "Tokenized first 16000 examples...\n",
      "Tokenized first 16100 examples...\n",
      "Tokenized first 16200 examples...\n",
      "Tokenized first 16300 examples...\n",
      "Tokenized first 16400 examples...\n",
      "Tokenized first 16500 examples...\n",
      "Tokenized first 16600 examples...\n",
      "Tokenized first 16700 examples...\n",
      "Tokenized first 16800 examples...\n",
      "Tokenized first 16900 examples...\n",
      "Tokenized first 17000 examples...\n",
      "Tokenized first 17100 examples...\n",
      "Tokenized first 17200 examples...\n",
      "Tokenized first 17300 examples...\n",
      "Tokenized first 17400 examples...\n",
      "Tokenized first 17500 examples...\n",
      "Tokenized first 17600 examples...\n",
      "Tokenized first 17700 examples...\n",
      "Tokenized first 17800 examples...\n",
      "Tokenized first 17900 examples...\n",
      "Tokenized first 18000 examples...\n",
      "Tokenized first 18100 examples...\n",
      "Tokenized first 18200 examples...\n",
      "Tokenized first 18300 examples...\n",
      "Tokenized first 18400 examples...\n",
      "Tokenized first 18500 examples...\n",
      "Tokenized first 18600 examples...\n",
      "Tokenized first 18700 examples...\n",
      "Tokenized first 18800 examples...\n",
      "Tokenized first 18900 examples...\n",
      "Tokenized first 19000 examples...\n",
      "Tokenized first 19100 examples...\n",
      "Tokenized first 19200 examples...\n",
      "Tokenized first 19300 examples...\n",
      "Tokenized first 19400 examples...\n",
      "Tokenized first 19500 examples...\n",
      "Tokenized first 19600 examples...\n",
      "Tokenized first 19700 examples...\n",
      "Tokenized first 19800 examples...\n",
      "Tokenized first 19900 examples...\n",
      "Tokenized first 20000 examples...\n",
      "Tokenized first 20100 examples...\n",
      "Tokenized first 20200 examples...\n",
      "Tokenized first 20300 examples...\n",
      "Tokenized first 20400 examples...\n",
      "Tokenized first 20500 examples...\n",
      "Tokenized first 20600 examples...\n",
      "Tokenized first 20700 examples...\n",
      "Tokenized first 20800 examples...\n",
      "Tokenized first 20900 examples...\n",
      "Tokenized first 21000 examples...\n",
      "Tokenized first 21100 examples...\n",
      "Tokenized first 21200 examples...\n",
      "Tokenized first 21300 examples...\n",
      "Tokenized first 21400 examples...\n",
      "Tokenized first 21500 examples...\n",
      "Tokenized first 21600 examples...\n",
      "Tokenized first 21700 examples...\n",
      "Tokenized first 21800 examples...\n",
      "Tokenized first 21900 examples...\n",
      "Tokenized first 22000 examples...\n",
      "Tokenized first 22100 examples...\n",
      "Tokenized first 22200 examples...\n",
      "Tokenized first 22300 examples...\n",
      "Tokenized first 22400 examples...\n",
      "Tokenized first 22500 examples...\n",
      "Tokenized first 22600 examples...\n",
      "Tokenized first 22700 examples...\n",
      "Tokenized first 22800 examples...\n",
      "Tokenized first 22900 examples...\n",
      "Tokenized first 23000 examples...\n",
      "Tokenized first 23100 examples...\n",
      "Tokenized first 23200 examples...\n",
      "Tokenized first 23300 examples...\n",
      "Tokenized first 23400 examples...\n",
      "Tokenized first 23500 examples...\n",
      "Tokenized first 23600 examples...\n",
      "Tokenized first 23700 examples...\n",
      "Tokenized first 23800 examples...\n",
      "Tokenized first 23900 examples...\n",
      "Tokenized first 24000 examples...\n",
      "Tokenized first 24100 examples...\n",
      "Tokenized first 24200 examples...\n",
      "Tokenized first 24300 examples...\n",
      "Tokenized first 24400 examples...\n",
      "Tokenized first 24500 examples...\n",
      "Tokenized first 24600 examples...\n",
      "Tokenized first 24700 examples...\n",
      "Tokenized first 24800 examples...\n",
      "Tokenized first 24900 examples...\n",
      "Tokenized first 25000 examples...\n",
      "Tokenized first 25100 examples...\n",
      "Tokenized first 25200 examples...\n",
      "Tokenized first 25300 examples...\n",
      "Tokenized first 25400 examples...\n",
      "Tokenized first 25500 examples...\n",
      "Tokenized first 25600 examples...\n",
      "Tokenized first 25700 examples...\n",
      "Tokenized first 25800 examples...\n",
      "Tokenized first 25900 examples...\n",
      "Tokenized first 26000 examples...\n",
      "Tokenized first 26100 examples...\n",
      "Tokenized first 26200 examples...\n",
      "Tokenized first 26300 examples...\n",
      "Tokenized first 26400 examples...\n",
      "Tokenized first 26500 examples...\n",
      "Tokenized first 26600 examples...\n",
      "Tokenized first 26700 examples...\n",
      "Tokenized first 26800 examples...\n",
      "Tokenized first 26900 examples...\n",
      "Tokenized first 27000 examples...\n",
      "Tokenized first 27100 examples...\n",
      "Tokenized first 27200 examples...\n",
      "Tokenized first 27300 examples...\n",
      "Tokenized first 27400 examples...\n",
      "Tokenized first 27500 examples...\n",
      "Tokenized first 27600 examples...\n",
      "Tokenized first 27700 examples...\n",
      "Tokenized first 27800 examples...\n",
      "Tokenized first 27900 examples...\n",
      "Tokenized first 28000 examples...\n",
      "Tokenized first 28100 examples...\n",
      "Tokenized first 28200 examples...\n",
      "Tokenized first 28300 examples...\n",
      "Tokenized first 28400 examples...\n",
      "Tokenized first 28500 examples...\n",
      "Tokenized first 28600 examples...\n",
      "Tokenized first 28700 examples...\n",
      "Tokenized first 28800 examples...\n",
      "Tokenized first 28900 examples...\n",
      "Tokenized first 29000 examples...\n",
      "Tokenized first 29100 examples...\n",
      "Tokenized first 29200 examples...\n",
      "Tokenized first 29300 examples...\n",
      "Tokenized first 29400 examples...\n",
      "Tokenized first 29500 examples...\n",
      "Tokenized first 29600 examples...\n",
      "Tokenized first 29700 examples...\n",
      "Tokenized first 29800 examples...\n",
      "Tokenized first 29900 examples...\n",
      "Tokenized first 30000 examples...\n",
      "Tokenized first 30100 examples...\n",
      "Tokenized first 30200 examples...\n",
      "Tokenized first 30300 examples...\n",
      "Tokenized first 30400 examples...\n",
      "Tokenized first 30500 examples...\n",
      "Tokenized first 30600 examples...\n",
      "Tokenized first 30700 examples...\n",
      "Tokenized first 30800 examples...\n",
      "Tokenized first 30900 examples...\n",
      "Tokenized first 31000 examples...\n",
      "Tokenized first 31100 examples...\n",
      "Tokenized first 31200 examples...\n",
      "Tokenized first 31300 examples...\n",
      "Tokenized first 31400 examples...\n",
      "Tokenized first 31500 examples...\n",
      "Tokenized first 31600 examples...\n",
      "Tokenized first 31700 examples...\n",
      "Tokenized first 31800 examples...\n",
      "Tokenized first 31900 examples...\n",
      "Tokenized first 32000 examples...\n",
      "Tokenized first 32100 examples...\n",
      "Tokenized first 32200 examples...\n",
      "Tokenized first 32300 examples...\n",
      "Tokenized first 32400 examples...\n",
      "Tokenized first 32500 examples...\n",
      "Tokenized first 32600 examples...\n",
      "Tokenized first 32700 examples...\n",
      "Tokenized first 32800 examples...\n",
      "Tokenized first 32900 examples...\n",
      "Tokenized first 33000 examples...\n",
      "Tokenized first 33100 examples...\n",
      "Tokenized first 33200 examples...\n",
      "Tokenized first 33300 examples...\n",
      "Tokenized first 33400 examples...\n",
      "Tokenized first 33500 examples...\n",
      "Tokenized first 33600 examples...\n",
      "Tokenized first 33700 examples...\n",
      "Tokenized first 33800 examples...\n",
      "Tokenized first 33900 examples...\n",
      "Tokenized first 34000 examples...\n",
      "Tokenized first 34100 examples...\n",
      "Tokenized first 34200 examples...\n",
      "Tokenized first 34300 examples...\n",
      "Tokenized first 34400 examples...\n",
      "Tokenized first 34500 examples...\n",
      "Tokenized first 34600 examples...\n",
      "Tokenized first 34700 examples...\n",
      "Tokenized first 34800 examples...\n",
      "Tokenized first 34900 examples...\n",
      "Tokenized first 35000 examples...\n",
      "Tokenized first 35100 examples...\n",
      "Tokenized first 35200 examples...\n",
      "Tokenized first 35300 examples...\n",
      "Tokenized first 35400 examples...\n",
      "Tokenized first 35500 examples...\n",
      "Tokenized first 35600 examples...\n",
      "Tokenized first 35700 examples...\n",
      "Tokenized first 35800 examples...\n",
      "Tokenized first 35900 examples...\n",
      "Tokenized first 36000 examples...\n",
      "Tokenized first 36100 examples...\n",
      "Tokenized first 36200 examples...\n",
      "Tokenized first 36300 examples...\n",
      "Tokenized first 36400 examples...\n",
      "Tokenized first 36500 examples...\n",
      "Tokenized first 36600 examples...\n",
      "Tokenized first 36700 examples...\n",
      "Tokenized first 36800 examples...\n",
      "Tokenized first 36900 examples...\n",
      "Tokenized first 37000 examples...\n",
      "Tokenized first 37100 examples...\n",
      "Tokenized first 37200 examples...\n",
      "Tokenized first 37300 examples...\n",
      "Tokenized first 37400 examples...\n",
      "Tokenized first 37500 examples...\n",
      "Tokenized first 37600 examples...\n",
      "Tokenized first 37700 examples...\n",
      "Tokenized first 37800 examples...\n",
      "Tokenized first 37900 examples...\n",
      "Tokenized first 38000 examples...\n",
      "Tokenized first 38100 examples...\n",
      "Tokenized first 38200 examples...\n",
      "Tokenized first 38300 examples...\n",
      "Tokenized first 38400 examples...\n",
      "Tokenized first 38500 examples...\n",
      "Tokenized first 38600 examples...\n",
      "Tokenized first 38700 examples...\n",
      "Tokenized first 38800 examples...\n",
      "Tokenized first 38900 examples...\n",
      "Tokenized first 39000 examples...\n",
      "Tokenized first 39100 examples...\n",
      "Tokenized first 39200 examples...\n",
      "Tokenized first 39300 examples...\n",
      "Tokenized first 39400 examples...\n",
      "Tokenized first 39500 examples...\n",
      "Tokenized first 39600 examples...\n",
      "Tokenized first 39700 examples...\n",
      "Tokenized first 39800 examples...\n",
      "Tokenized first 39900 examples...\n",
      "Tokenized first 40000 examples...\n",
      "Tokenized first 40100 examples...\n",
      "Tokenized first 40200 examples...\n",
      "Tokenized first 40300 examples...\n",
      "Tokenized first 40400 examples...\n",
      "Tokenized first 40500 examples...\n",
      "Tokenized first 40600 examples...\n",
      "Tokenized first 40700 examples...\n",
      "Tokenized first 40800 examples...\n",
      "Tokenized first 40900 examples...\n",
      "Tokenized first 41000 examples...\n",
      "Tokenized first 41100 examples...\n",
      "Tokenized first 41200 examples...\n",
      "Tokenized first 41300 examples...\n",
      "Tokenized first 41400 examples...\n",
      "Tokenized first 41500 examples...\n",
      "Tokenized first 41600 examples...\n",
      "Tokenized first 41700 examples...\n",
      "Tokenized first 41800 examples...\n",
      "Tokenized first 41900 examples...\n",
      "Tokenized first 42000 examples...\n",
      "Tokenized first 42100 examples...\n",
      "Tokenized first 42200 examples...\n",
      "Tokenized first 42300 examples...\n",
      "Tokenized first 42400 examples...\n",
      "Tokenized first 42500 examples...\n",
      "Tokenized first 42600 examples...\n",
      "Tokenized first 42700 examples...\n",
      "Tokenized first 42800 examples...\n",
      "Tokenized first 42900 examples...\n",
      "Tokenized first 43000 examples...\n",
      "Tokenized first 43100 examples...\n",
      "Tokenized first 43200 examples...\n",
      "Tokenized first 43300 examples...\n",
      "Tokenized first 43400 examples...\n",
      "Tokenized first 43500 examples...\n",
      "Tokenized first 43600 examples...\n",
      "Tokenized first 43700 examples...\n",
      "Tokenized first 43800 examples...\n",
      "Tokenized first 43900 examples...\n",
      "Tokenized first 44000 examples...\n",
      "Tokenized first 44100 examples...\n",
      "Tokenized first 44200 examples...\n",
      "Tokenized first 44300 examples...\n",
      "Tokenized first 44400 examples...\n",
      "Tokenized first 44500 examples...\n",
      "Tokenized first 44600 examples...\n",
      "Tokenized first 44700 examples...\n",
      "Tokenized first 44800 examples...\n",
      "Tokenized first 44900 examples...\n",
      "Tokenized first 45000 examples...\n",
      "Tokenized first 45100 examples...\n",
      "Tokenized first 45200 examples...\n",
      "Tokenized first 45300 examples...\n",
      "Tokenized first 45400 examples...\n",
      "Tokenized first 45500 examples...\n",
      "Tokenized first 45600 examples...\n",
      "Tokenized first 45700 examples...\n",
      "Tokenized first 45800 examples...\n",
      "Tokenized first 45900 examples...\n",
      "Tokenized first 46000 examples...\n",
      "Tokenized first 46100 examples...\n",
      "Tokenized first 46200 examples...\n",
      "Tokenized first 46300 examples...\n",
      "Tokenized first 46400 examples...\n",
      "Tokenized first 46500 examples...\n",
      "Tokenized first 46600 examples...\n",
      "Tokenized first 46700 examples...\n",
      "Tokenized first 46800 examples...\n",
      "Tokenized first 46900 examples...\n",
      "Tokenized first 47000 examples...\n",
      "Tokenized first 47100 examples...\n",
      "Tokenized first 47200 examples...\n",
      "Tokenized first 47300 examples...\n",
      "Tokenized first 47400 examples...\n",
      "Tokenized first 47500 examples...\n",
      "Tokenized first 47600 examples...\n",
      "Tokenized first 47700 examples...\n",
      "Tokenized first 47800 examples...\n",
      "Tokenized first 47900 examples...\n",
      "Tokenized first 48000 examples...\n",
      "Tokenized first 48100 examples...\n",
      "Tokenized first 48200 examples...\n",
      "Tokenized first 48300 examples...\n",
      "Tokenized first 48400 examples...\n",
      "Tokenized first 48500 examples...\n",
      "Tokenized first 48600 examples...\n",
      "Tokenized first 48700 examples...\n",
      "Tokenized first 48800 examples...\n",
      "Tokenized first 48900 examples...\n",
      "Tokenized first 49000 examples...\n",
      "Tokenized first 49100 examples...\n",
      "Tokenized first 49200 examples...\n",
      "Tokenized first 49300 examples...\n",
      "Tokenized first 49400 examples...\n",
      "Tokenized first 49500 examples...\n",
      "Tokenized first 49600 examples...\n",
      "Tokenized first 49700 examples...\n",
      "Tokenized first 49800 examples...\n",
      "Tokenized first 49900 examples...\n",
      "Tokenized first 50000 examples...\n",
      "Tokenized first 50100 examples...\n",
      "Tokenized first 50200 examples...\n",
      "Tokenized first 50300 examples...\n",
      "Tokenized first 50400 examples...\n",
      "Tokenized first 50500 examples...\n",
      "Tokenized first 50600 examples...\n",
      "Tokenized first 50700 examples...\n",
      "Tokenized first 50800 examples...\n",
      "Tokenized first 50900 examples...\n",
      "Tokenized first 51000 examples...\n",
      "Tokenized first 51100 examples...\n",
      "Tokenized first 51200 examples...\n",
      "Tokenized first 51300 examples...\n",
      "Tokenized first 51400 examples...\n",
      "Tokenized first 51500 examples...\n",
      "Tokenized first 51600 examples...\n",
      "Tokenized first 51700 examples...\n"
     ]
    }
   ],
   "source": [
    "tokenize_and_save_dataset(train_dataset, tokenizer, MAX_LENGTH, TRAIN_DATASET_PATH, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79796700-541c-4fd3-a3b3-a689f5a0953e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized first 100 examples...\n",
      "Tokenized first 200 examples...\n",
      "Tokenized first 300 examples...\n",
      "Tokenized first 400 examples...\n",
      "Tokenized first 500 examples...\n",
      "Tokenized first 600 examples...\n",
      "Tokenized first 700 examples...\n",
      "Tokenized first 800 examples...\n",
      "Tokenized first 900 examples...\n",
      "Tokenized first 1000 examples...\n",
      "Tokenized first 1100 examples...\n"
     ]
    }
   ],
   "source": [
    "tokenize_and_save_dataset(val_dataset, tokenizer, MAX_LENGTH, VAL_DATASET_PATH, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683fc049-bbb0-429d-9075-5d9548bd049e",
   "metadata": {},
   "source": [
    "## Load the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14c82f10-d1b7-4095-b4c9-b5b938cd314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_train_dataset = tf.data.Dataset.load(TRAIN_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67e0b7c5-a4c2-47c3-924c-2e17de52ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_val_dataset = tf.data.Dataset.load(VAL_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccadbb6-efe3-46da-9597-18b15d688736",
   "metadata": {},
   "source": [
    "## Print example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eefc0c3f-7dcd-4b2d-94e7-2a53f47f720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[   2   44  553 1021  285  120 3874  122 2698  285  120 2429 5629 1016\n",
      "  252 7567  122  169  211  120  342  355  544  376  100   16    3], shape=(27,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[   2  198  537  209 5685 4527 3361  122  209  695  919 1769  150  420\n",
      " 7451  736  178 5529  122  673  186  342  355  544  407  100   16    3], shape=(28,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for pt, en in loaded_train_dataset.take(1):\n",
    "    print(pt)\n",
    "    print(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f88320cb-1352-4e55-9120-e8bc309930a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([   2   59 1881  180  490 5563   44  180 2364 4364  343 2084  234    3], shape=(14,), dtype=int32)\n",
      "tf.Tensor([   2   43  181  316 3672 5135  182 4124   58  234    3], shape=(11,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for pt, en in loaded_val_dataset.take(1):\n",
    "    print(pt)\n",
    "    print(en)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
