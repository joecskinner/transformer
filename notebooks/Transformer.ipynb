{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8cd0ab-0294-4263-942b-d6a708f050cc",
   "metadata": {},
   "source": [
    "# Training the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109a625-5377-4ab5-b0d3-5ed5f9526d0e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce87b73a-788d-43df-ac57-b551e9127cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96340b46-1f97-46a9-873e-32132390e97a",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06abfa-e6d0-48ac-bb89-294812458167",
   "metadata": {},
   "source": [
    "### Load tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beead19c-4283-496c-a422-ad601446b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH =  \"./../tokenized_data/train\"\n",
    "VAL_DATASET_PATH = \"./../tokenized_data/val\"\n",
    "\n",
    "train_dataset = tf.data.Dataset.load(TRAIN_DATASET_PATH)\n",
    "val_dataset = tf.data.Dataset.load(VAL_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072a7b7a-a6d6-4751-9a71-55d539ff9348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[   2   44  553 1021  285  120 3874  122 2698  285  120 2429 5629 1016\n",
      "  252 7567  122  169  211  120  342  355  544  376  100   16    3], shape=(27,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[   2  198  537  209 5685 4527 3361  122  209  695  919 1769  150  420\n",
      " 7451  736  178 5529  122  673  186  342  355  544  407  100   16    3], shape=(28,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for pt, en in train_dataset.take(1):\n",
    "    print(pt)\n",
    "    print(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40763331-37fe-4cf3-9ad2-c13ae9987da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([   2   59 1881  180  490 5563   44  180 2364 4364  343 2084  234    3], shape=(14,), dtype=int32)\n",
      "tf.Tensor([   2   43  181  316 3672 5135  182 4124   58  234    3], shape=(11,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for pt, en in val_dataset.take(1):\n",
    "    print(pt)\n",
    "    print(en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fcef29-e34f-4eb6-b9e8-16354c261ee1",
   "metadata": {},
   "source": [
    "### Prepare the train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8aba2e-5474-4a0c-a8d9-87b7182b90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=128\n",
    "\n",
    "def prepare_batch(pt, en):\n",
    "    pt = pt[:, :MAX_TOKENS]\n",
    "    pt = pt.to_tensor() \n",
    "\n",
    "    en = en[:, :(MAX_TOKENS+1)]\n",
    "    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (pt, en_inputs), en_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9356e506-955a-4100-9ad7-23c2234106c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbda4142-ccdf-434d-8819-98536f31b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = make_batches(train_dataset)\n",
    "val_batches = make_batches(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66470b1c-7cd6-4f04-b7dd-43b1373a1bbb",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018cace0-d689-419e-84b3-725c12dd0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b8264cb-66df-45f4-a497-1254899d63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer import Transformer\n",
    "import src.utils.byte_pair_encoding_tokenizer as bpe\n",
    "\n",
    "\n",
    "tokenizer = bpe.CustomBPETokenizer([\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"], \"../bpe_tokenizers/ted_hrlr_translate_pt_to_en\")\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    d_ff=dff,\n",
    "    vocab_size=0,\n",
    "    input_vocab_size=tokenizer.get_vocab_size(),\n",
    "    target_vocab_size=tokenizer.get_vocab_size(),\n",
    "    dropout=dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06da0b-781b-4f31-8b35-65ac4a5be11f",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1fd0ab-440b-478c-802c-d01bf18246e4",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3689ec3-5859-44e1-99fb-50a04aa1f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.learning_rate_schedule import CustomLearningRateSchedule\n",
    "from src.utils.masked_loss import masked_loss\n",
    "from src.utils.masked_accuracy import masked_accuracy\n",
    "\n",
    "learning_rate = CustomLearningRateSchedule(d_model=d_model, warmup_steps=4000)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea48f2-177a-4e6f-b4fc-3f9905667e24",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aa311eb-e7f6-4b0a-9ba9-3159497e62ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67111ec5-a16b-492c-8a71-63a23fd372f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_inputs, example_batch_labels = next(iter(train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c8215a-50a6-4dd8-aca6-5f778253bbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 141ms/step\n"
     ]
    }
   ],
   "source": [
    "example_preds = transformer.predict(example_batch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90ca60c1-ecd5-4fdc-a4cf-47aa9e08e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions: (64, 83, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of predictions:\", example_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c96a5e8b-9fe4-4052-8a44-da6d529f05e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:49:40.441173: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1a30280de0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-08 15:49:40.441200: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1050 Ti with Max-Q Design, Compute Capability 6.1\n",
      "2023-11-08 15:49:40.446768: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-08 15:49:40.536901: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810/810 [==============================] - 796s 952ms/step - loss: 6.6896 - masked_accuracy: 0.1431 - val_loss: 5.0131 - val_masked_accuracy: 0.2482\n",
      "Epoch 2/3\n",
      "810/810 [==============================] - 787s 971ms/step - loss: 4.5794 - masked_accuracy: 0.2902 - val_loss: 4.0259 - val_masked_accuracy: 0.3583\n",
      "Epoch 3/3\n",
      "810/810 [==============================] - 785s 969ms/step - loss: 3.7806 - masked_accuracy: 0.3800 - val_loss: 3.3765 - val_masked_accuracy: 0.4376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1af84cf250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(train_batches,\n",
    "                epochs=3,\n",
    "                validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7bdba2-6394-4d2b-a59a-12228ad9e237",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "491ecf06-e2ab-465f-91f2-e4488d8779ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.translator import Translator\n",
    "\n",
    "translator = Translator(tokenizer, transformer)\n",
    "\n",
    "def print_example(input, target):\n",
    "    output = translator(input, 128)\n",
    "\n",
    "    print(f\"Input sentence: {input}\")\n",
    "    print(f\"Target sentence: {target}\")\n",
    "    print(f\"Translated setnece: {output.numpy().decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aaa368d-74d2-46c5-b2b8-3a725ad10f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: esta é uma frase curta de exemplo\n",
      "Target sentence: this is a short example sentence\n",
      "Translated setnece: this is a little bit of example of example .\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'esta é uma frase curta de exemplo'\n",
    "target = 'this is a short example sentence'\n",
    "\n",
    "print_example(input_sentence, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
